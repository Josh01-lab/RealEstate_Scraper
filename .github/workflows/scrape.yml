name: Nightly Lamudi Cebu Scrape

on:
  workflow_dispatch:
  schedule:
    # 3:00 AM Asia/Manila = 19:00 UTC the previous day
    - cron: "0 19 * * *"

jobs:
  scrape:
    runs-on: ubuntu-latest

    env:
      # Scraper knobs for CI
      SCRAPING_MODE: playwright
      RATE_LIMIT_DELAY: "1.0"
      MAX_PAGES: "1"
      MAX_LISTINGS: "0"        # set "0" to remove the hard cap
      LOG_LEVEL: INFO
      PORTALS_CONFIG: ./config/portals.json

      # DB (pulled from repo/environment secrets)
      SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
      SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}

    steps:
      - name: Check out repo
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      - name: Install dependencies
        run: |
          python -m pip install -U pip
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi

      - name: Install Playwright browsers
        run: |
          python -m playwright install --with-deps chromium

      - name: Discovery (lamudi_cebu)
        env:
          SCRAPING_MODE: playwright
          MAX_LISTINGS: "30"       # cap for CI smoke
          RATE_LIMIT_DELAY: "0.8"
          LOG_LEVEL: DEBUG
        run: |
          python -m src.runner.run_discovery --portal lamudi_cebu

      - id: capture
        name: Capture run dir
        shell: bash
        run: |
          dir=$(ls -1d scraper_output/run_* | tail -n1)
          echo "dir=$dir" >> "$GITHUB_OUTPUT"

      - name: Show discovered URLs
        run: |
          ls -lah "${{ steps.capture.outputs.dir }}/staged" || true
          head -n 10 "${{ steps.capture.outputs.dir }}/staged/lamudi_cebu_urls.jsonl"

      - name: Details (requests mode to avoid headless flakiness)
        env:
          SCRAPING_MODE: requests
          RATE_LIMIT_DELAY: "0.6"
          LOG_LEVEL: DEBUG
        run: |
          python -m src.runner.run_details --portal lamudi_cebu --run-dir "${{ steps.capture.outputs.dir }}"

      - name: Show listings output
        run: |
          ls -lah "${{ steps.capture.outputs.dir }}/staged" || true
          wc -l "${{ steps.capture.outputs.dir }}/staged/lamudi_cebu_listings.jsonl" || true
          head -n 5 "${{ steps.capture.outputs.dir }}/staged/lamudi_cebu_listings.jsonl" || true

      - name: Publish to Supabase
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
        run: |
          python -m src.runner.write_portal_dump_to_supabase --portal lamudi_cebu --run-dir "${{ steps.capture.outputs.dir }}"

      # Optional: quick sanity log (doesn't fail the job if it can't query)
      - name: Sanity echo staged head
        continue-on-error: true
        run: |
          head -n 5 "${{ steps.disco.outputs.RUN_DIR }}/staged/lamudi_cebu_listings.jsonl" || true
